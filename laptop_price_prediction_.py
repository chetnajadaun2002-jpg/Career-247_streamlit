# -*- coding: utf-8 -*-
"""Laptop Price Prediction .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uXsYEbHmLYAh_7TTu4xQg1owMbzBpMmx
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv("/content/drive/MyDrive/laptop_price.csv",encoding='latin')
df

df.drop(columns=['laptop_ID'],inplace=True)

print(df.isnull().sum())

df.duplicated().sum()

df[df.duplicated()]

df.drop_duplicates(inplace=True)

df.duplicated().sum()

df.info()

df.sample(5)

df['Price']=round(df['Price_euros']*103.44,-2).astype('int')

df.drop(columns=['Price_euros'],inplace=True)

sns.displot(df['Price'],kde=True)

sns.kdeplot(df['Price'])

# Right Skewed data : tail jha left side ho

sns.kdeplot(np.log(df['Price']))

# This is normal distribution of Price by applying log

np.exp(np.log(df['Price']))    # vps normal laane ke liye exponential

print(df['Company'].value_counts())

df['Company'].value_counts().plot(kind='bar')

len(df['Company'].value_counts())

print(df.groupby('Company')['Company'].count().sort_values(ascending=False))

df.groupby('Company')['Company'].transform('count')

51/1275

df=df[df.groupby('Company')['Company'].transform('count')>20]

df.reset_index(drop=True,inplace=True)
df

print(df['Company'].value_counts())

df['Company'].value_counts().plot(kind='bar')

df.groupby('Company')['Price'].mean().sort_values(ascending=False)

sorted_company_list=df.groupby('Company')['Price'].mean().sort_values(ascending=False).index
sorted_company_list

sorted_company_list[::-1]

sns.color_palette('Greens')

sns.barplot(x=df['Company'],y=df['Price'],errorbar=None,order=sorted_company_list,
            hue=df['Company'],palette='Greens',hue_order=sorted_company_list[::-1])

df.sample()

print(df['Product'].value_counts())

df.drop(columns=['Product'],inplace=True)

print(df['TypeName'].value_counts())

df['TypeName'].value_counts().plot(kind='bar')

df.groupby('TypeName')['Price'].mean().sort_values(ascending=False)

sorted_typelist=df.groupby('TypeName')['Price'].mean().sort_values(ascending=False).index
sorted_typelist

sns.barplot(x=df['TypeName'],y=df['Price'],errorbar=None,order=sorted_typelist,
            palette='Greens',hue=df['TypeName'],hue_order=sorted_typelist[::-1])
plt.xticks(rotation=90)
plt.show()

df.sample()

print(df['Inches'].value_counts())

sns.histplot(df['Inches'],kde=True)

sns.scatterplot(x=df['Inches'],y=df['Price'])

print(df['ScreenResolution'].value_counts())

a="IPS Panel Full HD / Touchscreen 1920x1080"
a.split()[-1].split('x')[0]

(lambda a:a.split()[-1].split('x')[0])("IPS Panel Full HD / Touchscreen 1920x1080")

df['X_res']=df['ScreenResolution'].apply(lambda a:a.split()[-1].split('x')[0]).astype('int')
df['Y_res']=df['ScreenResolution'].apply(lambda a:a.split()[-1].split('x')[0]).astype('int')
df['Touchscreen']=df['ScreenResolution'].apply(lambda a:1 if "Touchscreen" in a else 0)
df['IPS']=df['ScreenResolution'].apply(lambda a:1 if "IPS" in a else 0)

a="IPS Panel Full HD / Touchscreen 1920x1080"
[1 if "Touchscreen" in a else 0]

df.sample(5)

df.drop(columns=['ScreenResolution'],inplace=True)

df.sample()

df['Touchscreen'].value_counts().plot(kind='bar')

sns.barplot(x=df['Touchscreen'],y=df['Price'])

df['IPS'].value_counts().plot(kind='bar')

sns.barplot(x=df['IPS'],y=df['Price'],errorbar=None)

print(df['Cpu'].value_counts())

df['Cpu_Speed']=df['Cpu'].apply(lambda x:x.split()[-1].replace('GHz',"")).astype('float')

df.sample(5)

df['Cpu']=df['Cpu'].apply(lambda x:" ".join(x.split()[0:3]))

print(df['Cpu'].value_counts())

def fetch_processor_name(proc):
    if proc.split()[0]=='Intel':
        if proc.split()[1]=='Core':
            return proc
        else:
            return " ".join(proc.split()[0:2])
    else:
        if proc[4]=="E":
            return "AMD E-Series"
        elif proc[4]=="R":
            return "AMD Ryzen Series"
        elif proc[4]=="A":
            return "AMD A Series"
        else:
            return "AMD FX Series"

df['Cpu']=df['Cpu'].apply(fetch_processor_name)

print(df['Cpu'].value_counts())

df['Cpu'].value_counts().plot(kind='bar')

sorted_cpulist=df.groupby('Cpu')['Price'].mean().sort_values(ascending=False).index
sorted_cpulist

sns.barplot(x=df['Cpu'],y=df['Price'],errorbar=None,order=sorted_cpulist,
            palette='Greens',hue=df['Cpu'],hue_order=sorted_cpulist[::-1])
plt.xticks(rotation=90)
plt.show()

df['Ram']=df['Ram'].apply(lambda x:x.replace("GB","")).astype('int')
df['Weight']=df['Weight'].apply(lambda x:x.replace("kg","")).astype('float')

df['Ram'].value_counts().plot(kind='bar')

sns.barplot(x=df['Ram'],y=df['Price'],errorbar=None,hue=df['Ram'])

print(df['Gpu'].value_counts())

df['Gpu']=df['Gpu'].apply(lambda x:" ".join(x.split()[0:2]))

print(df['Gpu'].value_counts())

def fetch_gpu_name(text):
    if text.split()[0]=='AMD':
        return "AMD GPU"
    elif text=="Intel Graphics":
        return "Intel HD"
    elif text=="Nvidia GTX":
        return "Nvidia GeForce"
    else:
        return text

df['Gpu']=df['Gpu'].apply(fetch_gpu_name)

print(df['Gpu'].value_counts())

df['Gpu'].value_counts().plot(kind='bar')

df.groupby('Gpu')['Price'].mean()

sorted_gpulist=df.groupby('Gpu')['Price'].mean().sort_values(ascending=False).index
sorted_gpulist

sns.barplot(x=df['Gpu'],y=df['Price'],errorbar=None,order=sorted_gpulist,
            palette='Greens',hue=df['Gpu'],hue_order=sorted_gpulist[::-1])
plt.xticks(rotation=90)
plt.show()

df.sample()

print(df['OpSys'].value_counts())

def fetch_os_name(os):
    if os=="Windows 10 S":
        return "Windows 10"
    elif os=="macOS" or os=="Mac OS X":
        return "MacOS"
    elif os=="Android" or os=="Chrome OS" or os=="Linux":
        return "Linux/Chrome OS/Others"
    else:
        return os

df['OpSys']=df['OpSys'].apply(fetch_os_name)

print(df['OpSys'].value_counts())

sorted_oslist=df.groupby('OpSys')['Price'].mean().sort_values(ascending=False).index
sorted_oslist

sns.barplot(x=df['OpSys'],y=df['Price'],errorbar=None,order=sorted_oslist,
            palette='Greens',hue=df['OpSys'],hue_order=sorted_oslist[::-1])
plt.xticks(rotation=90)
plt.show()

print(df['Memory'].value_counts())

# SSD
# HDD
# SSD+HDD
# Flash Storage
# Hybrid
# SSD + SSD
# Flash Storage+SSD
# HDD + HDD
# SSD + Hybrid

# SSD  HDD   Flash Storage     Hybrid

df['Memory']=df['Memory'].astype(str).replace(r"\.0","",regex=True)

# 1TB=1000GB

print(df['Memory'].value_counts())

df['Memory']=df['Memory'].str.replace("GB","")
df['Memory']=df['Memory'].str.replace("TB","000")

print(df['Memory'].value_counts())

new=df['Memory'].str.split('+',expand=True)
df['first']=new[0]
df['first']=df['first'].str.strip()
df['second']=new[1]

df.sample(3)

df['Layer1HDD']=df['first'].apply(lambda x:1 if "HDD" in x else 0)
df['Layer1SSD']=df['first'].apply(lambda x:1 if "SSD" in x else 0)
df['Layer1Hybrid']=df['first'].apply(lambda x:1 if "Hybrid" in x else 0)
df['Layer1Flash_Storage']=df['first'].apply(lambda x:1 if "Flash" in x else 0)

df.sample(3)

df['first']=df['first'].str.replace(r"\D","",regex=True)
# \D: any character which is not a digit
# \d: any character which is a digit

df.sample(3)

df['second'].fillna("0",inplace=True)
df['second']=df['second'].str.strip()
df['Layer2HDD']=df['second'].apply(lambda x:1 if "HDD" in x else 0)
df['Layer2SSD']=df['second'].apply(lambda x:1 if "SSD" in x else 0)
df['Layer2Hybrid']=df['second'].apply(lambda x:1 if "Hybrid" in x else 0)
df['Layer2Flash_Storage']=df['second'].apply(lambda x:1 if "Flash" in x else 0)
df['second']=df['second'].str.replace(r"\D","",regex=True)

df.sample()

df['first']=df['first'].astype('int')
df['second']=df['second'].astype('int')

df['HDD']=df['first']*df['Layer1HDD']+df['second']*df['Layer2HDD']
df['SSD']=df['first']*df['Layer1SSD']+df['second']*df['Layer2SSD']
df['Hybrid']=df['first']*df['Layer1Hybrid']+df['second']*df['Layer2Hybrid']
df['Flash_Storage']=df['first']*df['Layer1Flash_Storage']+df['second']*df['Layer2Flash_Storage']

df.columns

df.drop(columns=['first', 'second', 'Layer1HDD', 'Layer1SSD', 'Layer1Hybrid',
       'Layer1Flash_Storage', 'Layer2HDD', 'Layer2SSD', 'Layer2Hybrid',
       'Layer2Flash_Storage'],inplace=True)

df.sample(10)

df.drop(columns=['Memory'],inplace=True)

df.info()

df.corr(numeric_only=True)

sns.heatmap(df.corr(numeric_only=True),cmap='summer')

df.corr(numeric_only=True)['Price']

df.drop(columns=['Hybrid','Flash_Storage'],inplace=True)

# screen size       : Inches
# screen resolution : X_res, Y_res
# resolution: number of pixels on the screen
# pixel density

df['ppi']=round((df['X_res']**2+df['Y_res']**2)**0.5/df['Inches'],2)

df.corr(numeric_only=True)['Price']

df.drop(columns=['X_res','Y_res','Inches'],inplace=True)

# screen size       : Inches
# screen resolution : X_res, Y_res
# resolution: number of pixels on the screen
# pixel density

# screen size       : Inches
# screen resolution : X_res, Y_res
# resolution: number of pixels on the screen
# pixel density



X=df.drop(columns=['Price'])
y=df['Price']

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.15,random_state=42)

X.shape,X_train.shape,X_test.shape

from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.tree import DecisionTreeRegressor
from sklearn.svm import SVR
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingRegressor, AdaBoostRegressor
from xgboost import XGBRegressor

from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline

from sklearn.metrics import r2_score, mean_absolute_error, root_mean_squared_error

# Encoding : process of converting text data to numerical data
# Label Encoding (output labels)
    # LabelEncoder
# Feature Encoding (input features)
    # Ordinal Encoding  : Very Good(2), Poor(0), Excellent(3), Satisfactory(1)
        # OrdinalEncoder
    # Nominal Encoding  : Man/Woman , Apple/Acer/Dell/HP
        # OneHotEncoder

# Company     Company_HP  Company_Ap
# Apple            0           1
# Apple            0           1
# HP               1           0
# Apple            0           1
# Dell             0           0
# HP               1           0
# Dell             0           0
# Apple            0           1

# Linear Regression
step1 = OneHotEncoder()
step2 = LinearRegression()
# step1+step2=pipeline

# pipe.fit(X_train,y_train)
# y_pred=pipe.predict(X_test)
# r2_score(y_test,y_pred)

X_train.sample()

# Linear Regression
ct_ohe= ColumnTransformer(transformers=[('col_tnf',OneHotEncoder(drop='first'),[0,1,2,4,5])],remainder='passthrough')
reg_model= LinearRegression()
pipe=Pipeline([('s1',ct_ohe),('s2',reg_model)])

pipe.fit(X_train,y_train)
y_pred=pipe.predict(X_test)
print("R2 score:",r2_score(y_test,y_pred))
print("MAE:",mean_absolute_error(y_test,y_pred))
print("RMSE:",root_mean_squared_error(y_test,y_pred))

# 1a - 1b
# 1b - 1c
# pipeline(1a)
# 1c

# Regularization Teechniques
# -Lasso()
# -Ridge()

X_train.sample()

# y=mx+c
# y=m1x1+m2x2+m3x3+... +c
# price=b1.RAM +b2.weight+b3.cpu+b4.cpu_speed+.....+b0

# Multi-collinearity
# Overfitting

# Ridge Regression : L2 Regularization : penalty: square of coefficients
ct_ohe= ColumnTransformer(transformers=[('col_tnf',OneHotEncoder(drop='first'),[0,1,2,4,5])],remainder='passthrough')
reg_model= Ridge(alpha=1)
pipe=Pipeline([('s1',ct_ohe),('s2',reg_model)])

pipe.fit(X_train,y_train)
y_pred=pipe.predict(X_test)
print("R2 score:",r2_score(y_test,y_pred))
print("MAE:",mean_absolute_error(y_test,y_pred))
print("RMSE:",root_mean_squared_error(y_test,y_pred))

# Lasso Regression : L1 regularization : penalty : absolute value of coefficients
# internal automatic feature selection

# When is Lasso useful?
  # - When you have many features, and you think not all are useful
  # - you suspect some features are not important
  # - you want a simpler model


# Lasso is very sensitive to feature scaling
# if your features are on very different scales, it is a good idea to normalize or standardize them
# we will standardize numeric features using standardscaler.

# Lasso Regression
categorical_features=[0,1,2,4,5]
numerical_features=[3,6,7,8,9,10,11,12]
preprocessor= ColumnTransformer(transformers=[
    ('cat',OneHotEncoder(drop='first'),categorical_features),
    ('num',StandardScaler(),numerical_features)
    ])
reg_model= Lasso(alpha=0.01)
pipe=Pipeline([('s1',preprocessor),('s2',reg_model)])

pipe.fit(X_train,y_train)
y_pred=pipe.predict(X_test)
print("R2 score:",r2_score(y_test,y_pred))
print("MAE:",mean_absolute_error(y_test,y_pred))
print("RMSE:",root_mean_squared_error(y_test,y_pred))

X_train.sample()

# Decision Tree Regression
ct_ohe= ColumnTransformer(transformers=[('col_tnf',OneHotEncoder(drop='first'),[0,1,2,4,5])],remainder='passthrough')
reg_model= DecisionTreeRegressor(max_depth=11)
pipe=Pipeline([('s1',ct_ohe),('s2',reg_model)])

pipe.fit(X_train,y_train)
y_pred=pipe.predict(X_test)
print("R2 score:",r2_score(y_test,y_pred))
print("MAE:",mean_absolute_error(y_test,y_pred))
print("RMSE:",root_mean_squared_error(y_test,y_pred))

# KNN(KNeighbours Classifier)

ct_ohe= ColumnTransformer(transformers=[('col_tnf',OneHotEncoder(drop='first'),[0,1,2,4,5])],remainder='passthrough')
reg_model= KNeighborsClassifier(n_neighbors=3)
pipe=Pipeline([('s1',ct_ohe),('s2',reg_model)])

pipe.fit(X_train,y_train)
y_pred=pipe.predict(X_test)
print("R2 score:",r2_score(y_test,y_pred))
print("MAE:",mean_absolute_error(y_test,y_pred))
print("RMSE:",root_mean_squared_error(y_test,y_pred))

# SVR(Support Vector Regressor)
categorical_features=[0,1,2,4,5]
numerical_features=[3,6,7,8,9,10,11,12]
preprocessor= ColumnTransformer(transformers=[
    ('cat',OneHotEncoder(drop='first'),categorical_features),
    ('num',StandardScaler(),numerical_features)
])
reg_model= SVR(C=100)
pipe=Pipeline([('s1',ct_ohe),('s2',reg_model)])

pipe.fit(X_train,y_train)
y_pred=pipe.predict(X_test)
print("R2 score:",r2_score(y_test,y_pred))
print("MAE:",mean_absolute_error(y_test,y_pred))
print("RMSE:",root_mean_squared_error(y_test,y_pred))

# Adaboost Regression
ct_ohe= ColumnTransformer(transformers=[('col_tnf',OneHotEncoder(drop='first'),[0,1,2,4,5])],remainder='passthrough')
reg_model= KNeighborsClassifier(n_neighbors=3)
pipe=Pipeline([('s1',ct_ohe),('s2',reg_model)])

pipe.fit(X_train,y_train)
y_pred=pipe.predict(X_test)
print("R2 score:",r2_score(y_test,y_pred))
print("MAE:",mean_absolute_error(y_test,y_pred))
print("RMSE:",root_mean_squared_error(y_test,y_pred))

# Ensemble : combination of multiple algorithms
# Crowd always knows best answer

# Gradient Boosting
    # Gradient Descent

# XGB Regression
categorical_features=[0,1,2,4,5]
numerical_features=[3,6,7,8,9,10,11,12]
preprocessor= ColumnTransformer(transformers=[
    ('cat',OneHotEncoder(drop='first'),categorical_features),
    ('num',StandardScaler(),numerical_features)
    ])
reg_model= GradientBoostingRegressor(random_state=15,n_estimators=600, learning_rate=0.1,max_depth=2)
pipe=Pipeline([('s1',preprocessor),('s2',reg_model)])

pipe.fit(X_train,y_train)
y_pred=pipe.predict(X_test)
print("R2 score:",r2_score(y_test,y_pred))
print("MAE:",mean_absolute_error(y_test,y_pred))
print("RMSE:",root_mean_squared_error(y_test,y_pred))

# GradientBoosting Regression
categorical_features=[0,1,2,4,5]
numerical_features=[3,6,7,8,9,10,11,12]
preprocessor= ColumnTransformer(transformers=[
    ('cat',OneHotEncoder(drop='first'),categorical_features),
    ('num',StandardScaler(),numerical_features)
    ])
reg_model= GradientBoostingRegressor(random_state=15,n_estimators=950, learning_rate=0.1,max_depth=2)
pipe=Pipeline([('s1',preprocessor),('s2',reg_model)])

pipe.fit(X_train,y_train)
y_pred=pipe.predict(X_test)
print("R2 score:",r2_score(y_test,y_pred))
print("MAE:",mean_absolute_error(y_test,y_pred))
print("RMSE:",root_mean_squared_error(y_test,y_pred))

# Grid Search CV
from sklearn.model_selection import GridSearchCV

# GradientBoosting Regression
categorical_features=[0,1,2,4,5]
numerical_features=[3,6,7,8,9,10,11,12]
preprocessor= ColumnTransformer(transformers=[
    ('cat',OneHotEncoder(drop='first'),categorical_features),
    ('num',StandardScaler(),numerical_features)
    ])
reg_model= GradientBoostingRegressor(random_state=15,n_estimators=950, learning_rate=0.1,max_depth=2)
pipe=Pipeline([('s1',preprocessor),('s2',reg_model)])

pipe.fit(X_train,y_train)
y_pred=pipe.predict(X_test)
print("R2 score:",r2_score(y_test,y_pred))
print("MAE:",mean_absolute_error(y_test,y_pred))
print("RMSE:",root_mean_squared_error(y_test,y_pred))

X.sample()

query=[['Dell','Notebook','Intel Core i5',18,'Intel HD','Windows 10',1.9,0,0,2.5,0,256,174.06]]

op=pipe.predict(query)

op

print("The estimated price of the laptop with the above mentioned specs is ₹"+str(round(op[0]))+".")

# Deployment

# Streamlit
# Streamlit cloud
# GitHub

import pickle
pickle.dump(pipe,open('pipe.pkl','wb'))
pickle.dump(df,open('df.pkl','wb'))

!pip install streamlit --quiet

# Commented out IPython magic to ensure Python compatibility.
# %%writefile abc.txt
# This is a test file

# Commented out IPython magic to ensure Python compatibility.
# %%writefile laptop_app.py
# import streamlit as st
# import pickle
# df=pickle.load(open('df.pkl','rb'))
# pipe=pickle.load(open('pipe.pkl','rb'))
# st.title("Laptop Price Predictor App")
# st.text("This app is using only a select few laptops(around 1200 laptops), so it may not align exactly with real world data")
# 
# company=st.selectbox("Manufacturer of the Laptop",df['Company'].unique())
# typename=st.radio("Type of the Laptop",df['TypeName'].unique(),horizontal=True)
# cpu=st.selectbox("Processor",df['Cpu'].unique())
# ram=st.pills("RAM on the system(in GB)",[4,8,12,16,24,32,64,128])
# gpu=st.radio("Graphics Card",df['Gpu'].unique(),index=1,horizontal=True)
# os=st.selectbox("Operating System",df['OpSys'].unique(),index=2)
# weight=st.slider("Weight of the laptop(in kg)",min_value=4.8,step=0.1,value=2.1)
# touchscreen=st.pills("Does the laptop have an touchscreen?",['Yes','No'])
# ips=st.pills("Does the laptop have an IPS display?",['Yes','No'])
# cpu_speed=st.slider("Clock Speed pf CPU(in GHz)",min_value=0.9,max_value=3.6,step=0.1,value=2.3)
# hdd=st.pills("Hard disk size on the system(in GB). If only SSD is present, select this is as 0",
#              [0,512,1024,2000],horizontal=True)
# ssd=st.pills("SSD storage on the system(in GB).",[0,256,512,1024,2000],default=512)
# screen_size=st.slider("Screen size(measured diagonally, in inches)",min_value=10.0,max_value=18.4,value=15.6,step=0.1)
# screen_resolution=st.selectbox("Laptop Screen Resolution (in pixels)",
#  ["2560x1600","1440x900","1920x1080","2880x1800","1366x768","2304x1440","3200x1800","1920x1200","2256x1504",
#   "3840x2160","2160x1440","2560x1440","1600x900","2736x1824","2400x1600"],index=2)
# 
# if st.button("PREDICT PRICE"):
#     if touchscreen == 'Yes':
#         touchscreen=1
#     else:
#         touchscreen=0
#     if ips == 'Yes':
#         ips=1
#     else:
#         ips=0
#     X_res=int(screen_resolution.split('x')[0])
#     Y_res=int(screen_resolution.split('x')[1])
#     ppi = ((X_res**2)+(Y_res**2))**0.5/screen_size
#     query=[[company,typename,cpu,ram,gpu,os,weight,touchscreen,ips,cpu_speed,hdd,ssd,ppi]]
#     op=pipe.predict(query)
#     st.subheader("The estimated price of the laptop with the above mentioned specs is ₹"+str(int(round(op[0],-2)))+".")

df.sample()

df['Cpu_Speed'].describe()

! streamlit run laptop_app.py & npx localtunnel --port 8501
